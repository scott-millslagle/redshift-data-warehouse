{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Infrustructure as Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import configparser\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import psycopg2\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Read in configuration file and assign config data to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "key = config.get('AWS','key')\n",
    "secret = config.get('AWS','secret')\n",
    "\n",
    "cluster_identifier = config.get('REDSHIFT','cluster_identifier')\n",
    "cluster_type = config.get('REDSHIFT','cluster_type')\n",
    "node_type = config.get('REDSHIFT','node_type')\n",
    "database_name = config.get('REDSHIFT','db_name')\n",
    "username = config.get('REDSHIFT','username')\n",
    "password = config.get('REDSHIFT','password')\n",
    "port = config.get('REDSHIFT','port')\n",
    "\n",
    "role_name = config.get('IAM', 'role_name')\n",
    "policy_name = config.get('IAM', 'policy_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create an IAM client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "iam = boto3.client('iam',aws_access_key_id=key,\n",
    "                     aws_secret_access_key=secret,\n",
    "                     region_name='us-east-1'\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create a role to attach to IAM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role named 'redshiftrole' has been created\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    warehouse_role = iam.create_role(\n",
    "        RoleName = role_name,\n",
    "        Description = 'Allows Redshift cluster to call AWS services on behalf of the user',\n",
    "        AssumeRolePolicyDocument = json.dumps(\n",
    "            {\n",
    "                'Statement': [\n",
    "                    {\n",
    "                        'Action': 'sts:AssumeRole',\n",
    "                        'Effect': 'Allow',\n",
    "                        'Principal': {\n",
    "                            'Service': 'redshift.amazonaws.com'\n",
    "                        }\n",
    "                     }\n",
    "                ],\n",
    "                'Version': '2012-10-17'\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    print(\"Role named '{}' has been created\".format(role_name))\n",
    "\n",
    "except Exception as e:\n",
    "    print(str(e))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Attach s3 access policy to IAM Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    iam.attach_role_policy(\n",
    "        RoleName=role_name,\n",
    "        PolicyArn='arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess'\n",
    "    )['ResponseMetadata']['HTTPStatusCode']   \n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Extract ARN from IAM Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role redshiftrole's ARN is: arn:aws:iam::406724209145:role/redshiftrole\n"
     ]
    }
   ],
   "source": [
    "role_arn = iam.get_role(\n",
    "    RoleName = role_name\n",
    ")['Role']['Arn']\n",
    "\n",
    "print(\"Role {}'s ARN is: {}\".format(role_name, role_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create a Redshift client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "redshift = boto3.client('redshift',\n",
    "                       region_name='us-east-1',\n",
    "                       aws_access_key_id=key,\n",
    "                       aws_secret_access_key=secret\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Check to see if a cluster already exists, delete if true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no clusters called Sparkify-clutser.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    redshift.delete_cluster(\n",
    "        ClusterIdentifier = cluster_identifier,\n",
    "        SkipFinalClusterSnapshot = True,\n",
    "    )\n",
    "\n",
    "    print(\"The cluster '{}' already exists\".format(cluster_identifier))\n",
    "    print(\"Deleting '{}'...\".format(cluster_identifier))\n",
    "    \n",
    "    # Create a waiter object that will check to see if cluster has been deleted if it exists \n",
    "    # Checks every 20 seconds, 30 tries if needed\n",
    "    redshift_waiter = redshift.get_waiter('cluster_deleted')\n",
    "    redshift_waiter.wait(\n",
    "        ClusterIdentifier = cluster_identifier,\n",
    "        WaiterConfig={\n",
    "            'Delay': 20,\n",
    "            'MaxAttempts':20\n",
    "        }\n",
    "    )\n",
    "    print(\"{} was successfully deleted\".format(cluster_identifier))\n",
    "    \n",
    "except:\n",
    "    print(\"There are no clusters called {}.\".format(cluster_identifier))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create a new cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new cluster called Sparkify-clutser.\n",
      "Sparkify-clutser is up and running.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cluster = redshift.create_cluster(\n",
    "        DBName=database_name,\n",
    "        ClusterIdentifier=cluster_identifier,\n",
    "        ClusterType=cluster_type,\n",
    "        NodeType=node_type,\n",
    "        MasterUsername=username,\n",
    "        MasterUserPassword=password,\n",
    "        Port=int(port),\n",
    "        IamRoles=[role_arn]\n",
    "    )\n",
    "\n",
    "    print(\"Creating a new cluster called {}.\".format(cluster_identifier))\n",
    "    \n",
    "    # Create a waiter object that will check to see if cluster is available\n",
    "    # Checks every 20 seconds, 30 tries if needed\n",
    "    waiter = redshift.get_waiter('cluster_available')\n",
    "    waiter.wait(\n",
    "        ClusterIdentifier=cluster_identifier,\n",
    "        WaiterConfig={\n",
    "                'Delay': 20,\n",
    "                'MaxAttempts':20\n",
    "            }\n",
    "    )\n",
    "\n",
    "    print(\"{} is up and running.\".format(cluster_identifier))\n",
    "\n",
    "except Exception as e:\n",
    "    print(str(e)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Get cluster endpoint and vpc security group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The endpoint for Sparkify-clutser is sparkify-clutser.cy91beix6dy8.us-east-1.redshift.amazonaws.com.\n",
      "The VPC security group ID for 'sg-0f91be8569b75756a' is 'Sparkify-clutser'.\n"
     ]
    }
   ],
   "source": [
    "clusters = redshift.describe_clusters(\n",
    "    ClusterIdentifier=cluster_identifier\n",
    ")['Clusters']\n",
    "        \n",
    "cluster_endpoint = clusters[0]['Endpoint']['Address']\n",
    "vpc_security_group_id = clusters[0][\"VpcSecurityGroups\"][0]['VpcSecurityGroupId']\n",
    "\n",
    "print(\"The endpoint for {} is {}.\".format(cluster_identifier, cluster_endpoint))\n",
    "print(\"The VPC security group ID for '{}' is '{}'.\".format(vpc_security_group_id, cluster_identifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## EC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create an ec2 instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ec2 = boto3.resource('ec2',\n",
    "                         region_name='us-east-1',\n",
    "                         aws_access_key_id=key,\n",
    "                         aws_secret_access_key=secret\n",
    "    )\n",
    "\n",
    "    ec2_security_group = ec2.SecurityGroup(vpc_security_group_id)\n",
    "\n",
    "    ec2_security_group.authorize_ingress(\n",
    "        GroupName = ec2_security_group.group_name,\n",
    "        CidrIp='0.0.0.0/0',\n",
    "        IpProtocol='TCP',\n",
    "        FromPort=int(port),\n",
    "        ToPort=int(port)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create a connection to the database and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://awsuser:Scott123@sparkify-clutser.cy91beix6dy8.us-east-1.redshift.amazonaws.com:5439/sparkify\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: awsuser@sparkify'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_string = \"postgresql://{}:{}@{}:{}/{}\".format(\n",
    "    username,\n",
    "    password,\n",
    "    cluster_endpoint,\n",
    "    port,\n",
    "    database_name\n",
    ")\n",
    "\n",
    "print(conn_string)\n",
    "\n",
    "\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Delete Redshift cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now deleting Sparkify-clutser...\n",
      "Sparkify-clutser has been deleted.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    redshift.delete_cluster(\n",
    "        ClusterIdentifier = cluster_identifier,\n",
    "        SkipFinalClusterSnapshot = True,\n",
    "    )\n",
    "    \n",
    "    print(\"Now deleting {}...\".format(cluster_identifier))\n",
    "    \n",
    "    # Create a waiter object that will check to see if cluster has been deleted\n",
    "    # Checks every 20 seconds, 30 tries if needed\n",
    "    delete_waiter = redshift.get_waiter('cluster_deleted')\n",
    "    delete_waiter.wait(\n",
    "        ClusterIdentifier=cluster_identifier,\n",
    "        WaiterConfig={\n",
    "            'Delay': 20,\n",
    "            'MaxAttempts':30\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"{} has been deleted.\".format(cluster_identifier))\n",
    "    \n",
    "except :\n",
    "    print(\"{} does not exist.\".format(cluster_identifier))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Detach S3 policy from IAM role "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    iam.detach_role_policy(RoleName=role_name, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "    iam.delete_role(RoleName=role_name)\n",
    "except :\n",
    "    print(\"{} does not exist.\".format(role_name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
